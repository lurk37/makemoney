import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import os
from glob import glob

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì£¼ì‹ ì •ë³´ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# CSV íŒŒì¼ ì½ê¸° ë¶€ë¶„
def get_latest_csv():
    csv_files = glob(os.path.join('.', 'sise_csv', '*.csv'))
    if not csv_files:
        raise FileNotFoundError('sise_csv í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
    latest_file = max(csv_files, key=os.path.getctime)
    
    try:
        date_str = latest_file.split('_')[-2]  # 20241230
        time_str = latest_file.split('_')[-1].replace('.csv', '')  # 215134
        
        formatted_date = f"{date_str[:4]}ë…„ {date_str[4:6]}ì›” {date_str[6:]}ì¼"
        formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:]}"
        trading_date = f"{formatted_date} {formatted_time}"
    except:
        trading_date = "ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨"
    
    return latest_file, trading_date

def get_company_info_and_news(ì¢…ëª©ì½”ë“œ, ì¢…ëª©ëª…):
    url = f"https://finance.naver.com/item/main.naver?code={ì¢…ëª©ì½”ë“œ}"
    
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    try:
        summary = soup.find('div', {'class': 'summary_info'}).get_text(strip=True)
    except AttributeError:
        summary = "ê¸°ì—… ìš”ì•½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    news_url = f"https://search.naver.com/search.naver?where=news&query={ì¢…ëª©ëª…}"
    news_response = requests.get(news_url)
    news_soup = BeautifulSoup(news_response.text, 'html.parser')
    
    news_list = []
    for news_item in news_soup.find_all('a', {'class': 'news_tit'}, limit=5):
        news_title = news_item.get_text(strip=True)
        news_link = news_item['href']
        news_list.append((news_title, news_link))
    
    return summary, news_list

def get_all_trading_dates():
    csv_files = glob(os.path.join('.', 'sise_csv', '*.csv'))
    if not csv_files:
        raise FileNotFoundError('sise_csv í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
    
    dates = []
    for file in csv_files:
        try:
            date_str = file.split('_')[-2]
            time_str = file.split('_')[-1].replace('.csv', '')
            
            formatted_date = f"{date_str[:4]}ë…„ {date_str[4:6]}ì›” {date_str[6:]}ì¼ {time_str[:2]}:{time_str[2:4]}:{time_str[4:]}"
            dates.append({
                'display': formatted_date,
                'filename': file,
                'timestamp': f"{date_str}_{time_str}"
            })
        except:
            continue
    
    dates.sort(key=lambda x: x['timestamp'], reverse=True)
    return dates

def main():
    st.title("ğŸ“ˆ ì£¼ì‹ ì •ë³´ ëŒ€ì‹œë³´ë“œ")
    
    with st.sidebar:
        st.header("ê²€ìƒ‰ ë° í•„í„°")
        
        # ì‚¬ì´ë“œë°”ì— ë‚ ì§œ ì„ íƒ ì˜µì…˜ ì¶”ê°€
        trading_dates = get_all_trading_dates()
        date_options = {date['display']: date['filename'] for date in trading_dates}
        selected_date_display = st.selectbox(
            'ê±°ë˜ì¼ì ì„ íƒ',
            options=list(date_options.keys())
        )
        
        # ê²€ìƒ‰ ê¸°ëŠ¥
        search_query = st.text_input('ì¢…ëª©ëª… ê²€ìƒ‰')
    
    selected_file = date_options[selected_date_display]
    
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(selected_file, dtype={'ì¢…ëª©ì½”ë“œ': str})
    df['ì¢…ëª©ëª…'] = df['ì¢…ëª©ëª…'].astype(str)
    
    # ê²€ìƒ‰ì–´ë¡œ í•„í„°ë§
    if search_query:
        filtered_df = df[df['ì¢…ëª©ëª…'].str.contains(search_query, case=False)]
    else:
        filtered_df = df
    
    st.header(f"ê±°ë˜ì¼ì: {selected_date_display}")
    
    # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
    with st.expander("ì£¼ì‹ ë°ì´í„° í…Œì´ë¸”", expanded=True):
        st.dataframe(
            filtered_df.style.format({
                'í˜„ì¬ê°€': '{:,.0f}',
                'ê±°ë˜ëŸ‰': '{:,.0f}',
                'PER': '{:.2f}',
                'ì‹œê°€': '{:,.0f}',
                'ê³ ê°€': '{:,.0f}',
                'ì €ê°€': '{:,.0f}'
            }),
            height=400
        )
    
    # ì„ íƒëœ ì¢…ëª© ìƒì„¸ ì •ë³´ í‘œì‹œ
    if not filtered_df.empty:
        st.header("ì¢…ëª© ìƒì„¸ ì •ë³´")
        for index, row in filtered_df.iterrows():
            ì¢…ëª©ì½”ë“œ = str(row['ì¢…ëª©ì½”ë“œ']).zfill(6)
            ì¢…ëª©ëª… = row['ì¢…ëª©ëª…']
            
            with st.expander(f"{ì¢…ëª©ëª…} ({ì¢…ëª©ì½”ë“œ})"):
                # ì£¼ê°€ ì •ë³´ ì„¹ì…˜
                st.subheader("ì£¼ê°€ ì •ë³´")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("í˜„ì¬ê°€", f"{row['í˜„ì¬ê°€']:,}ì›", 
                             delta=f"{((row['í˜„ì¬ê°€']-row['ì‹œê°€'])/row['ì‹œê°€']*100):.1f}%")
                with col2:
                    st.metric("ê±°ë˜ëŸ‰", f"{row['ê±°ë˜ëŸ‰']:,}")
                with col3:
                    st.metric("PER", f"{row['PER']:.2f}")
                
                # ê°€ê²© ë²”ìœ„ ì •ë³´
                st.subheader("ê°€ê²© ë²”ìœ„")
                col4, col5, col6 = st.columns(3)
                with col4:
                    st.metric("ì‹œê°€", f"{row['ì‹œê°€']:,}ì›")
                with col5:
                    st.metric("ê³ ê°€", f"{row['ê³ ê°€']:,}ì›")
                with col6:
                    st.metric("ì €ê°€", f"{row['ì €ê°€']:,}ì›")
                
                # ê¸°ì—… ìš”ì•½ê³¼ ë‰´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                summary, news_list = get_company_info_and_news(ì¢…ëª©ì½”ë“œ, ì¢…ëª©ëª…)
                
                # ê¸°ì—… ìš”ì•½ ì„¹ì…˜
                st.subheader("ê¸°ì—… ê°œìš”")
                st.write(summary)
                
                # ë‰´ìŠ¤ ì„¹ì…˜
                st.subheader("ê´€ë ¨ ë‰´ìŠ¤")
                for news_title, news_link in news_list:
                    st.write(f"[{news_title}]({news_link})")

if __name__ == '__main__':
    main()
